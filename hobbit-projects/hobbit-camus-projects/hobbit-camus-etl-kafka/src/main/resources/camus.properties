#job的名称
camus.job.name=test1
#是否开启工程自带的log4j配置
log4j.configuration=false

#cache in classpath dir
#hdfs.default.classpath.dir=

#cache in classpath files,以,分隔
#hdfs.external.jarFiles

#kafka日志同步的最终目标位置
etl.destination.path=/kafka
#kafka日志同步时工作目录的父目录
etl.execution.base.path=/kafka_execution
#kafka日志同步工作的历史目录,一般为etl.execution.base.path的子目录
etl.execution.history.path=/kafka_execution/history
#etl.execution.history.max.of.quota=0.5

#默认时区
etl.default.timezone=Asia/Shanghai
etl.output.file.time.partition.mins=60
etl.destination.path.topic.sub.dir=hourly
etl.avro.writer.sync.interval=16000

etl.output.codec=deflate
etl.deflate.level=6
#是否忽略schema的error
etl.ignore.schema.errors=true
max.decoder.exceptions.to.print=10

kafka.brokers=data-slave1.voole.com:9092,data-slave2.voole.com:9092,data-slave3.voole.com:9092,data-slave4.voole.com:9092
kafka.timeout.value=30000
kafka.fetch.buffer.size=1048576
kafka.client.name=Camus_Client

kafka.monitor.time.granularity=10

kafka.fetch.request.correlationid=-1
kafka.fetch.request.max.wait=1000
kafka.fetch.request.min.bytes=1024

#kafka.blacklist.topics=t_playbgn_v2
kafka.whitelist.topics=t_playbgn_v2
#,t_playbgn_v3,t_playalive_v2,t_playalive_v3,t_playend_v2,t_playend_v3
#kafka.move.to.last.offset.list=

#kafka pull的最大工作时间（单位:小时)
kafka.max.pull.hrs=-1
#每个task的kafka pull的最大工作时间(单位:分钟)
kafka.max.pull.minutes.per.task=-1
#kakfa最多同步之前几天的数据
kafka.max.historical.days=-1

#camus.message.encoder.class=
#camus.message.decoder.class=
camus.message.decoder.factory.class=com.voole.hobbit.camus.etl.kafka.coders.OrderMessageDecoderFactory
etl.record.writer.provider.class=com.voole.hobbit.camus.etl.kafka.common.AvroRecordWriterProvider

mapreduce.job.maps=20


